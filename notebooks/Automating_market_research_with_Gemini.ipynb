{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Automating Market Research with Gemini 1.5, Search, and Google Sheets\n",
        "\n",
        "\n",
        "### Install the Google Generative AI Library\n",
        "This cell installs the necessary Python package for interacting with Google's Gemini models. The `--upgrade` flag ensures that we have the latest version."
      ],
      "metadata": {
        "id": "q6z5HS6cBzxO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade google-generativeai"
      ],
      "metadata": {
        "id": "kMVKpWa0R989"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import necessary libraries and configure API key\n",
        "\n",
        "This cell imports the required modules for working with JSON and the Google Generative AI library, and user data in Colab. It also retrieves the Gemini API key from user data stored in the Colab environment, and configures the `genai` library to use it.\n",
        "\n",
        "**Please make sure you have stored your API key in the `GEMINI_API_KEY2` user data field in Colab.** You can do this via the Colab interface, or programmatically."
      ],
      "metadata": {
        "id": "cKWa0Br9CERn"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGeOIMXGUmVS"
      },
      "source": [
        "import json\n",
        "import google.generativeai as genai\n",
        "from google.ai.generativelanguage_v1beta.types import content\n",
        "from google.colab import userdata\n",
        "userdata.get('GEMINI_API_KEY2')\n",
        "\n",
        "genai.configure(api_key=userdata.get('GEMINI_API_KEY2'))"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setting Generation Parameters\n",
        "\n",
        "This code block defines the parameters for the large language model's text generation. These parameters control aspects like the randomness of the output (`temperature`), how many of the most likely next words are considered (`top_p`, and `top_k`), the maximum length of the generated text (`max_output_tokens`), and the format of the response (`response_mime_type`)."
      ],
      "metadata": {
        "id": "G2wQUkT8Cvre"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generation_config = {\n",
        "  \"temperature\": 1,\n",
        "  \"top_p\": 0.95,\n",
        "  \"top_k\": 40,\n",
        "  \"max_output_tokens\": 8192,\n",
        "  \"response_mime_type\": \"text/plain\",\n",
        "}"
      ],
      "metadata": {
        "id": "uoG8ZzCGSSrj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initializing the Gemini model with Google Search retrieval\n",
        "\n",
        "This code initializes a Gemini generative model. We specify the model name (`gemini-1.5-flash`) and pass the previously defined generation configuration. Crucially, we also equip the model with a Google Search retrieval tool. This allows the model to access and use real-time information from the web when generating its response.\n",
        "\n",
        "### Making the Gemini model request\n",
        "\n",
        "We also make the actual request to the language model. The prompt asks for information about the startup Vercel, requesting details about the company, its leadership, products, funding, and series level. The backslashes allow the prompt string to be split acrsos multiple lines in the code for readability."
      ],
      "metadata": {
        "id": "HlJtguNuDC-X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose a Gemini model.\n",
        "model = genai.GenerativeModel(\n",
        "  model_name=\"gemini-1.5-flash\",\n",
        "  generation_config=generation_config,\n",
        "  tools = [\n",
        "    genai.protos.Tool(\n",
        "      google_search_retrieval = genai.protos.GoogleSearchRetrieval()\n",
        "    ),\n",
        "  ],\n",
        ")\n",
        "\n",
        "# Make the LLM request.\n",
        "response = model.generate_content(\"Tell me a little bit about Vercel, the startup.\" \\\n",
        "                                  \"Make sure to be very detailed, and include information\" \\\n",
        "                                  \"about the CEO, CTO, and all of the products that they \" \\\n",
        "                                  \"have created. Also reference which Series level \" \\\n",
        "                                  \"they are (A, B, C, etc.), and the size and date of \" \\\n",
        "                                  \"their last funding round.\")\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "B3MKq-NGWbEi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "outputId": "dfece60a-904b-4baf-aa83-075e2070e167"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vercel is a cloud-based platform that simplifies frontend web application development, scaling, and security.  Founded by Guillermo Rauch (CEO), the company's headquarters are in San Francisco, California.  While the provided text doesn't name a CTO, it details several key products and funding information.\n",
            "\n",
            "**Products:**\n",
            "\n",
            "* **Next.js:** A popular open-source toolkit for building websites, allowing for cloud-based rendering of visual assets to speed up loading times. It uses React, an open-source library, for building website components.\n",
            "* **DX Platform:** Vercel's flagship offering, simplifying the deployment of frontend code to production. It includes pre-packaged CI/CD pipelines, staging environments for testing, and the ability to quickly roll back updates if necessary.  It also offers managed website hosting infrastructure and cloud databases.\n",
            "* **Serverless Storage Solutions:**  This suite includes Vercel KV, Vercel Postgres, Vercel Blob, and Vercel Edge Config, providing various options for storing website data.\n",
            "* **v0:** A generative AI product allowing for the creation of user interfaces from text descriptions.\n",
            "* **Vercel AI SDK:** A comprehensive framework for building AI applications and products.\n",
            "\n",
            "**Funding and Valuation:**\n",
            "\n",
            "Vercel recently completed a $250 million Series E funding round on May 16th, 2024, valuing the company at $3.25 billion.  The round was led by Accel, with participation from GV (Alphabet Inc.'s startup fund), CRV, and several other investors including Notable Capital, Bedrock, Geodesic Capital, Tiger Global, 8VC, and SV Angel.  In total, Vercel has raised $563 million over 5 funding rounds.  As of June 10th, 2024, its implied valuation had increased slightly to $3.31 billion.\n",
            "\n",
            "**Further Information:**\n",
            "\n",
            "Vercel's annual recurring revenue surpassed $100 million shortly before the Series E funding. The company plans to use the funds to enhance its cybersecurity features (including DDoS protection and access controls), and to further develop its AI offerings.  They have partnered with nine AI providers to accelerate product development.  Vercel serves a large number of enterprise clients, including Under Armour, Unity, Sonos, and Nintendo.  The company boasts over one million monthly active developers utilizing its Next.js framework.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Defining the Response Schema\n",
        "\n",
        "This code block defines the expected structure of the LLM's response using a schema.  The schema specifies that the response should be a JSON object with a required \"company_name\" field.\n",
        "\n",
        "The `company_name` field itself is an object containing fields like `CEO_name`, `current_valuation`, `last_funding_month_and_year`, `series_level`, and `product_names`.  The `product_names` field is expected to be an array of strings.  This schema ensures the LLM output is structured and parsable. The `response_mime_type` is set to ensure the output is in JSON format."
      ],
      "metadata": {
        "id": "GZgf_uaoEPlI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generation_config = {\n",
        "  \"temperature\": 1,\n",
        "  \"top_p\": 0.95,\n",
        "  \"top_k\": 40,\n",
        "  \"max_output_tokens\": 8192,\n",
        "  \"response_schema\": content.Schema(\n",
        "    type = content.Type.OBJECT,\n",
        "    enum = [],\n",
        "    required = [\"company_name\"],\n",
        "    properties = {\n",
        "      \"company_name\": content.Schema(\n",
        "        type = content.Type.OBJECT,\n",
        "        enum = [],\n",
        "        required = [\"CEO_name\", \"current_valuation\",\n",
        "                    \"last_funding_month_and_year\",\n",
        "                    \"series_level\", \"product_names\"],\n",
        "        properties = {\n",
        "            \"product_names\": genai.protos.Schema(\n",
        "            type = genai.protos.Type.ARRAY,\n",
        "            items = genai.protos.Schema(\n",
        "              type = genai.protos.Type.STRING,\n",
        "            ),\n",
        "          ),\n",
        "            \"CEO_name\": content.Schema(\n",
        "            type = content.Type.STRING,\n",
        "          ),\n",
        "            \"current_valuation\": content.Schema(\n",
        "            type = content.Type.STRING,\n",
        "          ),\n",
        "            \"last_funding_month_and_year\": content.Schema(\n",
        "            type = content.Type.STRING,\n",
        "          ),\n",
        "            \"series_level\": content.Schema(\n",
        "            type = content.Type.STRING,\n",
        "          ),\n",
        "        },\n",
        "      ),\n",
        "    },\n",
        "  ),\n",
        "\n",
        "  \"response_mime_type\": \"application/json\",\n",
        "}"
      ],
      "metadata": {
        "id": "gs6VEYLoSN-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Instantiating the Generative Model\n",
        "\n",
        "This code initializes a `GenerativeModel` object from the `genai` library. It specifies the model to use (`gemini-1.5-flash-8b`) and the generation configuration defined in the previous step. This sets up the model for generating content based on the provided schema and parameters.\n",
        "\n",
        "### Making the LLM Request and Processing the Response\n",
        "\n",
        "This code makes the actual request to the language model using `model.generate_content()`. It passes `response.text` (presumably containing the prompt or context for the LLM) as input.  The LLM's response is then parsed as a JSON object using `json.loads()`. Finally, the JSON object is formatted with indentation using `json.dumps()` for readability and printed to the console."
      ],
      "metadata": {
        "id": "QDJ9I0O0Eegm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel(\n",
        "  model_name=\"gemini-1.5-flash-8b\",\n",
        "  generation_config=generation_config,\n",
        ")\n",
        "\n",
        "# Make the LLM request.\n",
        "response = model.generate_content(response.text)\n",
        "\n",
        "json_object = json.loads(response.text)\n",
        "\n",
        "json_formatted_str = json.dumps(json_object, indent=2)\n",
        "\n",
        "print(json_formatted_str)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        },
        "id": "zyHEBT_XTmEv",
        "outputId": "be42f2c4-3936-4009-aa83-316a150003ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"company_name\": {\n",
            "    \"CEO_name\": \"Guillermo Rauch\",\n",
            "    \"current_valuation\": \"$3.31 billion\",\n",
            "    \"last_funding_month_and_year\": \"May 2024\",\n",
            "    \"product_names\": [\n",
            "      \"Next.js\",\n",
            "      \"DX Platform\",\n",
            "      \"Serverless Storage Solutions\",\n",
            "      \"v0\",\n",
            "      \"Vercel AI SDK\"\n",
            "    ],\n",
            "    \"series_level\": \"Series E\"\n",
            "  }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Authentication and Setup\n",
        "\n",
        "This section handles authentication with Google Colab and sets up the necessary libraries for interacting with Google Sheets.\n",
        "\n",
        "### Create a New Google Sheet\n",
        "\n",
        "This code creates a new Google Sheet titled \"Startup market research\", opens the Sheet, and adds data."
      ],
      "metadata": {
        "id": "e8LmBM8CFGd5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "import gspread\n",
        "from google.auth import default\n",
        "creds, _ = default()\n",
        "\n",
        "gc = gspread.authorize(creds)\n",
        "\n",
        "sh = gc.create('Startup market research')\n",
        "\n",
        "# Open our new sheet and add some data.\n",
        "worksheet = gc.open('Startup market research').sheet1\n",
        "\n",
        "# Flatten JSON data.\n",
        "data = []\n",
        "for key, value in json_object[\"company_name\"].items():\n",
        "    if key == \"product_names\":  # Handle product_names list separately\n",
        "        # Join the products into a single string separated by commas\n",
        "        value = \", \".join(value)\n",
        "    data.append([key, value])  # Now value is a simple string or the joined string\n",
        "\n",
        "# Update the worksheet with the flattened data\n",
        "worksheet.update('A1', data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Tcw5hSTZX-o",
        "outputId": "87c300db-59e0-4989-935b-4fb1347f617c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-96-d486fd4e312b>:23: DeprecationWarning: The order of arguments in worksheet.update() has changed. Please pass values first and range_name secondor used named arguments (range_name=, values=)\n",
            "  worksheet.update('A1', data)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'spreadsheetId': '13F-kjLPG5RVebF8cp7jvBnWzYUbfvCJkdejQIWcrxKc',\n",
              " 'updatedRange': 'Sheet1!A1:B5',\n",
              " 'updatedRows': 5,\n",
              " 'updatedColumns': 2,\n",
              " 'updatedCells': 10}"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q1L72Ko3eY6K"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}