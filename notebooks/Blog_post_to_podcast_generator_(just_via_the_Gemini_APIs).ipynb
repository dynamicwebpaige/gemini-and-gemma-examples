{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d522c44b"
      },
      "source": [
        "# ğŸ™ï¸ Generating a Podcast from a Blog Post with the Gemini APIs\n",
        "\n",
        "This tutorial demonstrates how to create an audio podcast from a blog post using Google AI's Gemini models for summarization and text-to-speech (TTS). We will use the `google-genai` library to interact with the Gemini API.\n",
        "\n",
        "**Workflow:**\n",
        "\n",
        "1.  **Scrape Blog Content:** Extract the main text content from a given blog URL.\n",
        "2.  **Summarize Content:** Use a Gemini model to generate a concise and engaging podcast script from the scraped text.\n",
        "3.  **Generate Audio:** Use a Gemini TTS model to convert the podcast script into audio.\n",
        "4.  **Save Audio:** Save the generated audio data as a WAV file.\n",
        "\n",
        "## Setup and Configuration\n",
        "\n",
        "First, let's install the necessary libraries and set up our configuration."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Import required libraries\n",
        "import os\n",
        "import google.generativeai as genai\n",
        "from google import genai as google_genai # Import the client library with an alias\n",
        "from google.genai import types # Import types\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from google.colab import userdata\n",
        "from uuid import uuid4\n",
        "import wave"
      ],
      "metadata": {
        "cellView": "form",
        "id": "vxzyizEY0GG0"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8f5196f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46532e67-2922-46c2-e07e-877fed9d9b24"
      },
      "source": [
        "#@title Configuration Settings\n",
        "GOOGLE_API_KEY = userdata.get(\"GOOGLE_API_KEY\")\n",
        "BLOG_URL = \"https://research.google/blog/how-we-created-hov-specific-etas-in-google-maps/\"\n",
        "VOICE_CHOICE = \"Kore\" # Choose a pre-built voice (e.g., 'Echo', 'Onyx', 'Aurora', 'Nova', etc.)\n",
        "LANGUAGE = \"Japanese\"\n",
        "\n",
        "if GOOGLE_API_KEY == \"YOUR_GOOGLE_API_KEY\" or not GOOGLE_API_KEY:\n",
        "    print(\"Please replace 'YOUR_GOOGLE_API_KEY' with your actual Google API key in Colab secrets.\")\n",
        "elif not BLOG_URL:\n",
        "    print(\"Please provide a valid blog URL to process.\")\n",
        "else:\n",
        "    print(\"Configuration loaded successfully.\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Configuration loaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "683fc982"
      },
      "source": [
        "## Helper Functions\n",
        "\n",
        "We'll define a couple of helper functions: one to save audio data to a WAV file and another to scrape the content from a blog URL."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8436ba0"
      },
      "source": [
        "# Save the audio data to a .wav file.\n",
        "def wave_file(filename: str, pcm_data: bytes, channels=1, sample_width=2, rate=24000):\n",
        "    \"\"\"\n",
        "    Saves PCM audio data to a .wav file.\n",
        "\n",
        "    Args:\n",
        "        filename: The path to save the file to.\n",
        "        pcm_data: The audio data in bytes.\n",
        "        channels: Number of audio channels.\n",
        "        sample_width: Sample width in bytes.\n",
        "        rate: The sampling rate (e.g., 24000 for Gemini's TTS).\n",
        "    \"\"\"\n",
        "    os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
        "    with wave.open(filename, \"wb\") as wf:\n",
        "        wf.setnchannels(channels)\n",
        "        wf.setsampwidth(sample_width)\n",
        "        wf.setframerate(rate)\n",
        "        wf.writeframes(pcm_data)\n",
        "    print(f\"Successfully saved audio to: {filename}\")\n",
        "\n",
        "# Scrape blog content from a URL.\n",
        "def scrape_blog_content(url: str) -> str | None:\n",
        "    \"\"\"\n",
        "    Scrapes the main text content of a blog post from a given URL.\n",
        "\n",
        "    Args:\n",
        "        url: The URL of the blog post to scrape.\n",
        "\n",
        "    Returns:\n",
        "        The scraped text content as a single string, or None if scraping fails.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        print(f\"Scraping content from: {url}\")\n",
        "        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
        "        response = requests.get(url, headers=headers)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "        paragraphs = soup.find_all('p')\n",
        "\n",
        "        if not paragraphs:\n",
        "            print(\"Warning: No paragraph tags found. Attempting to get text from the body.\")\n",
        "            return soup.body.get_text(separator='\\n', strip=True) if soup.body else \"\"\n",
        "\n",
        "        content = \"\\n\".join([p.get_text() for p in paragraphs])\n",
        "        print(\"Scraping successful.\")\n",
        "        return content\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error: Failed to scrape the URL. {e}\")\n",
        "        return None"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cb95290c"
      },
      "source": [
        "## Podcast Generation Function\n",
        "\n",
        "This function orchestrates the entire process: scraping the blog, summarizing the content using a Gemini model, and generating audio from the summary using the Gemini TTS model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12b45fd6"
      },
      "source": [
        "def generate_podcast_from_url(blog_url: str, api_key: str, voice: str, language: str = \"English\"):\n",
        "    \"\"\"\n",
        "    Generates a podcast from a blog URL using Gemini for summarization and TTS.\n",
        "\n",
        "    Args:\n",
        "        blog_url: The URL of the blog to process.\n",
        "        api_key: Your Google API key.\n",
        "        voice: The pre-built voice to use for the podcast.\n",
        "               Available voices include 'Echo', 'Onyx', 'Aurora', 'Nova', etc.\n",
        "        language: The desired language for the podcast script and audio (default is \"English\").\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Configure the generativeai library for summarization\n",
        "        genai.configure(api_key=api_key) # Use genai for configure\n",
        "        # Create a client for the genai library for TTS\n",
        "        client = google_genai.Client(api_key=api_key) # Use the aliased google_genai for Client\n",
        "    except Exception as e:\n",
        "        print(f\"Error configuring Google API or creating client: {e}\")\n",
        "        return\n",
        "\n",
        "    # 1. Scrape the blog content\n",
        "    blog_content = scrape_blog_content(blog_url)\n",
        "    if not blog_content:\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        # 2. Generate a summary with a standard Gemini model\n",
        "        print(\"Initializing summarization model...\")\n",
        "        summarizer_model = genai.GenerativeModel(model_name=\"gemini-2.5-flash\")\n",
        "\n",
        "        summary_prompt = (\n",
        "            f\"You are a podcast host. Create a concise, engaging script in {language} from the \"\n",
        "            \"following blog content. Capture the main points conversationally. \"\n",
        "            \"Do not mention style details like 'intro music fades in'. \"\n",
        "            f\"The content should be optimized for text-to-speech generation. \\n\\n\"\n",
        "            f\"BLOG CONTENT:\\n---\\n{blog_content}\"\n",
        "        )\n",
        "\n",
        "        print(f\"Generating summary in {language}...\")\n",
        "        summary_response = summarizer_model.generate_content(summary_prompt)\n",
        "\n",
        "        # Check if the response contains valid text content\n",
        "        if summary_response.candidates and summary_response.candidates[0].content.parts:\n",
        "            summary_text = summary_response.text\n",
        "            print(f\"Generated Summary:\\n---\\n{summary_text}\\n---\")\n",
        "        else:\n",
        "            print(\"Error: Summarization failed. The model did not return valid text content.\")\n",
        "            if summary_response.candidates and summary_response.candidates[0].finish_reason:\n",
        "                print(f\"Finish reason: {summary_response.candidates[0].finish_reason}\")\n",
        "            return # Exit the function if summarization failed\n",
        "\n",
        "\n",
        "        # 3. Generate audio using the dedicated text-to-speech model via the client\n",
        "        print(f\"Generating audio from summary with voice: {voice} in {language}...\")\n",
        "        audio_response = client.models.generate_content(\n",
        "            model=\"gemini-2.5-flash-preview-tts\",\n",
        "            contents=summary_text,\n",
        "            config=types.GenerateContentConfig(\n",
        "                response_modalities=[\"AUDIO\"],\n",
        "                speech_config=types.SpeechConfig(\n",
        "                    voice_config=types.VoiceConfig(\n",
        "                        prebuilt_voice_config=types.PrebuiltVoiceConfig(\n",
        "                            voice_name=voice,\n",
        "                        )\n",
        "                    )\n",
        "                ),\n",
        "            )\n",
        "        )\n",
        "\n",
        "        # 4. Save the generated audio to a file\n",
        "        # Access the audio data from the response structure\n",
        "        if audio_response.candidates and audio_response.candidates[0].content.parts:\n",
        "             audio_data = audio_response.candidates[0].content.parts[0].inline_data.data\n",
        "             if audio_data:\n",
        "                output_dir = \"audio_generations\"\n",
        "                output_filename = f\"{output_dir}/podcast_{uuid4()}.wav\"\n",
        "                # Use the wave_file helper to save the PCM data\n",
        "                wave_file(output_filename, audio_data)\n",
        "             else:\n",
        "                 print(\"Error: Audio data is empty.\")\n",
        "        else:\n",
        "            print(\"Error: Audio generation failed. No audio data was returned in the expected format.\")\n",
        "\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during the generation process: {e}\")"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4e7a5c80"
      },
      "source": [
        "## Execute the Podcast Generation\n",
        "\n",
        "Finally, we call the `generate_podcast_from_url` function with our configuration to start the process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "36a84b32",
        "outputId": "cb59f74e-7989-4bd0-c12c-199f8cc689e1"
      },
      "source": [
        "# --- Execution ---\n",
        "if GOOGLE_API_KEY != \"YOUR_GOOGLE_API_KEY\" and GOOGLE_API_KEY and BLOG_URL:\n",
        "    generate_podcast_from_url(\n",
        "        blog_url=BLOG_URL,\n",
        "        api_key=GOOGLE_API_KEY,\n",
        "        voice=VOICE_CHOICE,\n",
        "        language=LANGUAGE\n",
        "    )\n",
        "else:\n",
        "    print(\"Please ensure your API key is set and a valid blog URL is provided in the Configuration section.\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scraping content from: https://research.google/blog/how-we-created-hov-specific-etas-in-google-maps/\n",
            "Scraping successful.\n",
            "Initializing summarization model...\n",
            "Generating summary in Japanese...\n",
            "Generated Summary:\n",
            "---\n",
            "çš†ã•ã‚“ã€ã“ã‚“ã«ã¡ã¯ï¼æ—¥ã€…ã®é€šå‹¤ã€ç§»å‹•ã§Google ãƒãƒƒãƒ—ã‚’ä½¿ã£ã¦ã„ã‚‹æ–¹ã€æœ—å ±ã§ã™ï¼\n",
            "\n",
            "æœ€è¿‘ã€EVã‚„ç›¸ä¹—ã‚Šã€å…¬å…±äº¤é€šæ©Ÿé–¢ãªã©ã€ç’°å¢ƒã«å„ªã—ã„ç§»å‹•æ‰‹æ®µã¸ã®ã‚·ãƒ•ãƒˆãŒé€²ã‚“ã§ã„ã¾ã™ã‚ˆã­ã€‚ç‰¹ã«ã€è¤‡æ•°ã®ä¹—å®¢ãŒä¹—ã‚‹è»Šå°‚ç”¨ã®ã€ŒHOVãƒ¬ãƒ¼ãƒ³ã€ã€æ—¥æœ¬èªã§ã„ã†ã€Œé«˜ä¹—è»Šè»Šä¸¡ãƒ¬ãƒ¼ãƒ³ã€ã¯ã€äº¤é€šé‡ã®å¤šã„æ™‚é–“å¸¯ã«ä¸€èˆ¬ãƒ¬ãƒ¼ãƒ³ã‚ˆã‚Šã‚‚é€Ÿã„å‚¾å‘ãŒã‚ã‚Šã¾ã™ã€‚ã§ã‚‚ã€ã“ã®HOVãƒ¬ãƒ¼ãƒ³ã‚’ä½¿ã£ãŸå ´åˆã®æ­£ç¢ºãªåˆ°ç€äºˆæ¸¬æ™‚é–“ï¼ˆETAï¼‰ã‚’å‡ºã™ã®ã¯é›£ã—ã‹ã£ãŸã‚“ã§ã™ã€‚\n",
            "\n",
            "ãã“ã§Google ãƒãƒƒãƒ—ãŒã€HOVãƒ¬ãƒ¼ãƒ³ã‚’å«ã‚€ãƒ«ãƒ¼ãƒˆã‚’é¸æŠã§ãã€ãã®ETAã‚‚è¡¨ç¤ºã™ã‚‹æ–°æ©Ÿèƒ½ã‚’å°å…¥ã—ã¾ã—ãŸï¼\n",
            "\n",
            "ã©ã†ã‚„ã£ã¦ã“ã‚Œã‚’å®Ÿç¾ã—ãŸã‹ã¨ã„ã†ã¨ã€ã“ã‚ŒãŒGoogle Researchã®æŠ€è¡“ã®çœŸéª¨é ‚ãªã‚“ã§ã™ã€‚HOVãƒ¬ãƒ¼ãƒ³ã‚’ä½¿ã£ã¦ã„ã‚‹ã‹ã©ã†ã‹ã‚’æ­£ç¢ºã«ç‰¹å®šã™ã‚‹ã®ã¯å®Ÿã¯ç°¡å˜ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚é€Ÿåº¦ãƒ‡ãƒ¼ã‚¿ã ã‘ã§ã¯åˆ¤æ–­ã§ããªã„å ´åˆã‚‚å¤šã„ã‚“ã§ã™ã€‚\n",
            "\n",
            "ãã“ã§å½¼ã‚‰ã¯ã€æ•™å¸«ãªã—å­¦ç¿’ã¨ã„ã†AIã®æ‰‹æ³•ã‚’ä½¿ã„ã¾ã—ãŸã€‚ã¤ã¾ã‚Šã€ã‚ã‚‰ã‹ã˜ã‚HOVã‹ãã†ã§ãªã„ã‹ã€ã¨ã„ã†æ­£è§£ãƒ‡ãƒ¼ã‚¿ãŒãªãã¦ã‚‚ã€AIãŒè‡ªã‚‰ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è¦‹ã¤ã‘ã¦åˆ†é¡ã™ã‚‹ã‚“ã§ã™ã€‚é€Ÿåº¦ãƒ‡ãƒ¼ã‚¿ã ã‘ã§ãªãã€è»Šç·šã®ä¸­å¤®ã‹ã‚‰ã®æ¨ªæ–¹å‘ã®è·é›¢ã€æ™‚é–“ã®çµŒéãªã©ã‚’è¤‡åˆçš„ã«åˆ†æã—ã€ã•ã‚‰ã«ã€Œã‚½ãƒ•ãƒˆã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã€ã‚„è¤‡æ•°ã®ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã†ã€Œæ··åˆã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã€ã¨ã„ã£ãŸé«˜åº¦ãªæ‰‹æ³•ã‚’çµ„ã¿åˆã‚ã›ã¦ã€ç²¾åº¦ã‚’é«˜ã‚ã¦ã„ã¾ã™ã€‚\n",
            "\n",
            "ã“ã®æ–°æ©Ÿèƒ½ã®ãŠã‹ã’ã§ã€HOVãƒ¬ãƒ¼ãƒ³ã‚’åˆ©ç”¨ã™ã‚‹ãƒ‰ãƒ©ã‚¤ãƒãƒ¼ã®ETAç²¾åº¦ã¯ãªã‚“ã¨75%ã‚‚å‘ä¸Šã—ãŸãã†ã§ã™ï¼é€šå‹¤æ™‚é–“ã®äºˆæ¸¬ãŒã‚ˆã‚Šæ­£ç¢ºã«ãªã‚Šã€æ¸‹æ»ã®ç·©å’Œã‚„æ’å‡ºã‚¬ã‚¹ã®å‰Šæ¸›ã«ã‚‚è²¢çŒ®ã—ã¾ã™ã€‚\n",
            "\n",
            "ã“ã®æŠ€è¡“ã¯ã€å°†æ¥çš„ã«äºŒè¼ªè»Šãªã©ä»–ã®äº¤é€šæ‰‹æ®µã«ã‚‚å¿œç”¨ã§ãã‚‹å¯èƒ½æ€§ã‚’ç§˜ã‚ã¦ã„ã¾ã™ã€‚ã‚ˆã‚Šã‚¹ãƒãƒ¼ãƒˆã§ç’°å¢ƒã«å„ªã—ã„ç§»å‹•ä½“é¨“ã‚’å¯èƒ½ã«ã™ã‚‹Googleã®å–ã‚Šçµ„ã¿ã«ã€ã“ã‚Œã‹ã‚‰ã‚‚æ³¨ç›®ã§ã™ã­ã€‚\n",
            "---\n",
            "Generating audio from summary with voice: Kore in Japanese...\n",
            "Successfully saved audio to: audio_generations/podcast_051ac897-9983-4bc4-bc46-53f45612a77e.wav\n"
          ]
        }
      ]
    }
  ]
}